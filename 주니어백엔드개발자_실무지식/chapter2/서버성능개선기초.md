# 서버 성능 개선 기초

**수직 확장과 수평 확장**
 - 수직 확장(Scale up): CPU, memory, disk 등 리소스를 증가시키는 것, 즉각적인 효과가 나타나지만 언제까지 늘릴수만은 없음
 - 수평 확장(Scale out): 서버를 늘리는 방법
   - 먼저 병목 지점을 파악하고 서버를 추가해야 함
     - 만약 DB에서 성능 문제가 발생하는데 DB를 사용하는 서버를 늘리면, DB에 가해지는 부하만 더 커지고 성능 문제가 심해짐(외부 API 호출도 마찬가지) 
 - 로드 밸런서: 사용자의 트래픽을 각 서버에 골고루 분배해 한 서버에 트래픽이 몰리는 것을 방지함, 전체 서버 자원을 효율적으로 사용 가능
   - 알고리즘
     - 정적 방식: 라운드로빈(클라이언트의 요청을 각 서버에 순차적으로 분배), IP 해시(클라이언트의 IP주소를 해시한 값을 기반으로 요청을 전달할 서버를 결정, 항상 동일한 서버로 지정)
     - 동적 방식: 서버의 현재 상태에 따라 트래픽을 분산, 트래픽이 더 적거나 응답 시간이 더 짧은 서버에 요청을 보냄
    
**DB connection pool**
- 네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답시간에 영향을 주는 문제를 해결하기 위해 DB 커넥션 풀을 사용
- 커넥션 풀: DB에 연결된 커넥션을 미리 생성해서 보관
  - 애플리케이션은 커넥션을 풀에서 가져오고, 작업완료시 다시 풀에 반환
  - 이미 연결된 커넥션을 재사용하므로 응답시간이 줄어들음
  - 설정 정보
    - 커넥션 풀 크기(또는 최소, 최대 크기): 미리 생성해둘 커넥션 개수 지정(가장 중요함!)
      - 트래픽이 순간적으로 급증할때, 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋음(DB 연결 시간이 성능 저하의 주원인이 될 수도)
      - 그렇다고 무턱대고 늘리기만 하면 안됨, DB 서버의 CPU 사용률이 80%를 넘나드는 상황이면 DB에 가해지는 부하가 더 심해짐(크기를 유지하거나 더 줄이자)
    - 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간: 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간
      - HikariCP의 default 대기 시간: 30초
      - 지정된 대기 시간안에 커넥션을 구하지 못하면 DB 연결 실패 에러 발생
      - 대기시간 만큼 응답시간도 길어짐, 보통 0.5초에서 3초 이내로 지정하는 것이 좋음
      - 커넥션을 다 사용중일때, 무응답 상태로 유지되는 것보다 빠르게 에러를 반환하는 것이 나음 -> 서버의 부하 증가를 방지하게
    - 커넥션의 유지 시간(최대 유휴 시간, 최대 유지시간): 커넥션이 사용되지 않는 시간이 길어지면 연결이 끊어질 수 있음, 이때 DB와 연결이 끊긴 커넥션을 사용하면 에러가 발생함
      - 이러한 에러 방지를 위해 커넥션 풀은 2가지 기능 제공
        - 최대 유후 시간 지정: 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간
          - 이 시간을 DB에 설정된 비활성화 유지 시간보다 짧게 설정하면, DB가 연결을 끊기 전에 풀에서 커넥션 제거 가능
        - 유효성 검사 지원: 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차
          - 이 과정을 통해 연결이 유효하지 않은 커넥션을 식별하고 풀에서 제거 가능
          - 유효성 검사를 위해 `SELECT 1 FROM dual` 쿼리를 실행하기도 함
        - 최대 유지 시간: 만약 이 값이 4시간이면 커넥션은 생성된 시점부터 최대 4시간까지만 유지, 4시간이 지나면 커넥션이 유효하더라도 커넥션을 닫고 풀에서 제거됨

**서버 캐시**
- Cache(Key: Value로 저장됨)에 자주 조회되는 데이터를 보관하여 응답 시간을 줄임
  - 데이터가 캐시에 없다면(Cache miss), DB에서 가져와 캐시에 저장
  - 데이터가 캐시에 있다면(Cache hit), 캐시에서 가져옴
- 적절한 Key 선택(중복 주의)
  - Ex) 게시글 상세 정보는 "articles:번호" 형태의 키 사용, 최신 인기 글은 "articles:hot10"을 키로 사용하는 식

**적중률과 삭제 규칙**
- 적중률(hit rate): 캐시가 얼마나 효율적으로 사용되는지 판단
  - `hit rate = <캐시에 존재하는 건수>/<캐시에서 조회를 시도한 건수>`

  적중률이 높을 수록 DB와의 연동이 줄어들고 곧 응답 시간 감소, 처리량 증가, DB 부하 감소로 이어짐
  - 적중률을 높이는 방법: 캐시에 최대한 많은 데이터를 저장 BUT, 메모리 용량의 한계가 있기 때문에 무한대로 저장할 수는 없음
- 삭제 규칙: 캐시가 가득차있을 때, 기존의 데이터를 삭제해야 함
  - 삭제 알고리즘
    - LRU(Least Recently Used): 가장 오래전에 사용된 데이터 제거
    - LFU(Least Frequently Used): 가장 적게 사용된 데이터 제거
    - FIFO(First In First Out): 먼저 추가된 데이터 먼저 제거
  - 캐시가 가득 차 있지 않더라도 오래된 데이터는 미리미리 삭제하는 것이 좋음(사용하지 않을 가능성이 높은데, 굳이 캐시 용량을 차지할 필요가 없으니..)
    - 그래서 캐시에 만료 시간을 설정함 -> 일정 시간이 지나면 캐시에서 자동으로 삭제 -> 효율적인 메모리 관리 가능

**로컬 캐시와 리모트 캐시**

로컬 캐시: 서버 프로세스와 동일한 메모리를 캐시 저장소로 사용, In-memory Cache(메모리에 캐시 데이터를 보관하기 때문)
- 로컬 캐시 구현 방법: Caffeine, go_cache, node-cache
- 장점: 속도가 빠르다(네트워크를 안타니까), 외부 연동이 필요없으므로 구조가 단순함
- 단점: 캐시에 저장할 수 있는 데이터 크기에 제한이 있음(메모리 크기의 물리적 한계), 서버 프로세스를 재시작하면 메모리에 존재하던 캐시 데이터가 모두 삭제되어 일시적으로 적중률이 순간적으로 떨어짐
리모트 캐시: 별도 프로세스를 캐시 저장소로 사용
- 장점: 캐시 크기를 유연하게 확장 가능(여러 대의 Redis서버를 두어 수평 확장 가능), 서버 프로세스가 재시작되더라도 캐시 데이터는 그대로 유지됨 -> 적중률을 높임
- 단점: 속도(네트워크 통신 필수), 별도의 서버 장비와 프로세스가 필요하므로 시스템 구조가 복잡함

로컬 캐시, 리모트 캐시는 용도에 맞게 사용해야 함

만약 홈 화면에 표시할 최신 공지 목록은 많아야 10개 미만이고 잘 변경되지 않기 때문에 로컬 캐시를 사용하기에 적절
- 즉, 자주 바뀌지 않고 크기가 작은 데이터는 로컬 캐시에 저장

리모트 캐시에는 데이터 규모가 큰 데이터를 저장함. 트래픽이 많은 사이트의 개별 제품 정보(상품 상세) 데이터 저장 -> 대량의 상품 데이터를 캐시에 저장하기에는 로컬 캐시 메모리 한계가 있음
또한, 일부 데이터를 로컬 캐시에 저장하더라도 데이터가 수시로 변경되면 적중률 감소.
배포 빈도가 높은 서비스일 때, 리모트 캐시를 사용하면 좋음
- 만약 로컬 캐시에 저장한다면, 서버 재시작마다 캐시 데이터를 처음부터 쌓아야함(날아가니까..) -> 그래서 적중률도 응답시간도 영향이 감
- 리모트 캐시를 이용할 경우, 서버 재시작마다 캐시 데이터가 유지되므로 응답 시간을 일정 수준으로 유지 가능

**캐시 사전 적재**
- 트래픽이 순간적으로 급증할 때
  - 캐시에 데이터를 미리 저장하는 것을 고려해보자
  - Ex) 앱 사용자 300만명
    - 앱 서비스는 사용자에게 매달 정해진 날에 이달의 요금 정보를 보여줌
    - 해당 일자가 되면 전체 회원을 대상으로 요금 안내 푸시 알림 발송
    - 푸시를 받은 사용자 중 일부는 앱을 통해 이달의 요금 정보 조회
      푸시 알람을 받은 50% 사용자가 바로 확인할 경우, 단시간만에 150만명이 동시 접속하게 됨. 이때, 요금 정보에 대한 캐시 적중률은 순간적으로 0%에 가까워지게 됨
      - 아직 사용자의 개별 요금 정보가 캐시에 없기 때문
      - 사용자가 한번이라도 요금 정보를 확인해야 캐시에 적재되기 때문에 캐시에 당연히 데이터가 없음
   - 그래서 미리 캐시에 데이터를 넣어두자 -> DB 부하도 감소되고 응답시간도 늘어남

**캐시 무효화**
- 캐시 사용시 주의할 점: 유효하지 않은 데이터를 적절한 시점에 캐시에서 삭제하는 것
  - 원본 데이터가 변경되었다면 캐시에 저장된 데이터도 변경, 삭제되어야 함 -> 잘못된 정보를 조회할 수 있기 때문
  - 캐시 데이터의 특성에 따라 무효화 시점을 다르게 설정해야 함
    - 가격 정보, 게시글 내용처럼 민감한 데이터는 변경되는 즉시 캐시를 무효화해야 함
    - 변경에 민감한 데이터는 리모트 캐시에 보관
      - 로컬 캐시는 다른 서버의 로컬 캐시를 변경하지 않음
    - 만약, 변경에 민감하지 않고 크기가 작다면 캐시의 만료시간 설정하여 주기적으로 갱신하는 방법도 좋음
      - Ex) 인기 글 목록 갱신

 **가비지 컬렉터와 메모리 사용**

 가비지 컬렉터: 사용이 끝난 객체를 힙 메모리에서 바로 삭제하지 않고 정해진 규칙에 따라 사용하지 않는 메모리를 찾아 반환
 - 가비지 컬렉터는 **응답 시간에 영향을 줄 수 있음**
   - `Stop-The-World`: 자바에서 가비지 컬렉터가 실행되는 동안 애플리케이션의 실행이 잠시동안 일시 중단되는 것을 말함
   - 메모리를 많이 사용하고 생성된 객체가 많을수록 사용하지 않는 객체를 찾는데 시간이 오래걸리게 됨 -> GC 실행 시간이 길어지게 됨
   - 반대로, 메모리 사용량을 줄이면 GC 시간이 줄어들 수 있음
     - Ex) JVM에 할당된 최대 힙 크기를 4GB -> 2GB로 줄이면 GC가 탐지하고 제거해야 할 미사용 객체의 개수와 크기도 줄어듦
       - 검사해야 할 객체 수가 줄어드는 만큼 GC 수행시간이 짧아짐
       - 실제 애플리케이션이 필요로 하는 메모리가 4GB인데 2GB로 줄여버리면 메모리 부족으로 에러가 발생할 수 있으므로 주의
   - 한번에 대량으로 객체를 생성하는 것도 주의
     - Ex) 콘텐츠 조회 API가 한번에 10만개의 게시글을 반환한다고 가정, 게시글 하나당 0.5KB 메모리 사용
       - 10만 * 0.5KB = 50MB 메모리를 차지함
       - 만약 동시에 100명의 사용자가 API를 호출한다면, 4.9GB의 메모리가 필요해짐
       - 사용할 수 있는 최대 메모리가 4GB일 경우, GC가 작동하더라도 메모리가 부족한 상태는 지속됨
         - heap dump를 분석하여 메모리 분석해야 함
     - 따라서 조회 범위를 제한하면 됨
       - 10년 치 거래 내역을 한번에 조회하는 것보다 최대 3개월 치만 거래 내역을 조회할 수 있게 변경하기
     - 파일 다운로드 같은 경우 스트림을 활용
       ```java
       // 파일을 한번에 메모리로 로딩 - 피해야됨
       byte[] bytes = Files.readAllBytes(Path.of("path"));
       out.write(bytes); // 30MB 크기 파일을 100명이 동시에 다운로드할 경우 3GB 메모리 필요
       ```
       - 스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있음
       ```java
       // 8kb 씩 끊어서 파일을 읽어옴 - 동시 요청자 100명일 때 최대 800kb 메모리 필요
       InputStream is = Files.newInputStream(Path.of("path"));
       byte[] buffer = new byte[8192]; // 8kb
       int read;
       while ((read = is.read(buffer, 0, 8192)) >= 0) {
           out.write(buffer, 0, read);
       }
       ```

**응답 데이터 압축**
응답 시간에는 데이터 전송 시간이 포함됨
- 전송시간은 '네트워크 속도'와 '전송 데이터 크기'에 영향을 받음

서버는 전송하는 데이터의 크기를 제어하여 개선할 수 있음(네트워크는 내잘못아님)
- 응답 데이터 압축하여 전송하는 방법
  - 웹 서버가 전송하는 응답 데이터 중, HTML, CSS, JS, JSON 등 텍스트 응답은 압축하면 데이터 전송량을 크게 줄일 수 있음
  - 실제로 gzip으로 압축하면 70% 이상 크기를 줄일 수 있음 -> 전송 시간도 빨라짐 -> 응답 시간이 빨라짐!
  - 아파치나 Nginx 등 웹 서버에서 압축 기능 제공 중
  - Accept-Encoding Header를 통해 서버에 처리할 수 있는 압축 알고리즘을 알림
    - Request: `Accept-Encoding: gizp, deflate`(클라이언트는 gzip, deflate 압축을 이해할 수 있음)
    - Response: `Content-Encoding: gzip`(서버는 HTML 문서를 gzip으로 압축해서 보냈음)
  - 웹서버에서 압축적용했어도 방화벽이 이를 해제해 응답할 수 있음(실제 응답 데이터가 압축이 안됐다면 방화벽 설정 확인할 것)

**정적 자원과 브라우저 캐시**
SpringBoot와 Thymeleaf를 이용해 서버를 개발했다면,
- 동적 자원 응답: 브라우저가 요청할 때마다 결과가 바뀌는 데이터(제품의 HTML, 상세 JSON 응답 등)
- 정적 자원 응답: 같은 URL에 대해 같은 데이터를 응답하는 콘텐츠(image, JS, CSS 등)
  - 전체 트래픽에서 상당한 비중을 차지함
  - 동일한 페이지에 들어갈 때마다 같은 정적파일을 매번 다운로드하면 서버입장에서도 비용에서도 별로임
- 서버가 전송하는 트래픽을 줄이면서 브라우저에 빠르게 화면을 표시하는 방법
  - 클라이언트 캐시 활용하기
  - HTTP에서 데이터를 응답할 때 `Cache-Control`이나 `Expires` header를 이용해 클라이언트가 응답 데이터를 일정 시간 동안 저장해둘 수 있도록 설정 가능
    - `Cache-Control: max-age=60` 라고 지정되어 있다면, 같은 주소로 부터 a.png 같은 파일을 다운로드하면, 해당 파일을 로컬 캐시에 보관함, 60초 이내에 요청을 보내면 로컬에 보관한 데이터 사용
      - 처리속도 상승 및 트래픽이 줄어 네트워크 전송 비용 감소

**정적 자원과 CDN**

브라우저 캐시에서 생각해봐야 할 문제점
- 브라우저 캐시는 브라우저 단위로 동작하므로 동시에 많은 사용자가 접속하면 순간적으로 많은 양의 image, JS, CSS를 전송함
- 네트워크로 트래픽이 몰려서 응답 시간이 느려지게 됨

해결 방법 중 하나인, **CDN(Content Delivery Network)** 사용
- 콘텐츠를 제공하기 위한 별도의 네트워크
- 대표적 서비스: Amazon CloudFront, Akamai, Cloudflare 등
- CDN은 지역별로 Edge 서버를 제공(클라이언트는 자신과 가까운 Edge 서버에 연결됨), Origin 서버에 직접 연결할 때보다 빠르게 콘텐츠에 접근 가능해짐
- CDN이 제공하는 URL을 통해 콘텐츠에 접근, CDN에 데이터가 없다면 Origin 서버에서 가져와 제공하고 캐시에 보관

**대기 처리**

콘서트 예매 케이스
- 급격하게 증가한 트래픽은 매진과 동시에 빠르게 감소하는 패턴을 가짐
- 시스템의 처리량만 늘리는 것도 방법이지만 한번 늘어난 DB 성능을 줄이기가 쉽지가 않음
- 서버의 처리량을 늘리는 것보다, 수용할 수 있는 수준의 트래픽만 처리하고 나머지는 대기 처리를 하는 방법(굳)
  - 장점
    - 서버 증설없이 서비스를 안정적으로 제공
    - 사용자의 지속적인 새로고침으로 인한 트래픽 폭증 방지(새로고침하면 순번이 뒤로밀림)
 
### 읽어볼 자료들
- [HikariCP로 MySQL Connection Pool 최적화하기](https://cheese10yun.github.io/mysql-connection-pool-timeout-1/)
- [Redis Pub/Sub을 활용한 쿠폰 발급 비동기 처리](https://oliveyoung.tech/2023-08-07/async-process-of-coupon-issuance-using-redis/)
  
